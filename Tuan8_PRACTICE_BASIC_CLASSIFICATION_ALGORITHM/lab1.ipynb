{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbea95b",
   "metadata": {},
   "source": [
    "2.1. GIẢI THUẬT 1: CÂY QUYẾT ĐỊNH VÀ RỪNG CÂY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b70678",
   "metadata": {},
   "source": [
    "2.1.1. Ôn tập lý thuyết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c946381",
   "metadata": {},
   "source": [
    "Câu 1: Quy trình khai phá dữ liệu CRISP–DM và SEMMA là gì?\n",
    "🔹 CRISP–DM (Cross Industry Standard Process for Data Mining)\n",
    "\n",
    "Là quy trình chuẩn công nghiệp được sử dụng phổ biến trong các dự án khai phá dữ liệu.\n",
    "CRISP–DM gồm 6 giai đoạn chính:\n",
    "\n",
    "Giai đoạn\tTên bước\tNội dung\n",
    "1\tBusiness Understanding\tHiểu rõ mục tiêu kinh doanh, xác định vấn đề cần giải quyết.\n",
    "2\tData Understanding\tThu thập dữ liệu, kiểm tra chất lượng, khám phá thông tin ban đầu.\n",
    "3\tData Preparation\tLàm sạch dữ liệu, chọn đặc trưng, biến đổi dữ liệu phù hợp cho mô hình.\n",
    "4\tModeling\tXây dựng và huấn luyện các mô hình (ví dụ: Decision Tree, Random Forest, v.v.).\n",
    "5\tEvaluation\tĐánh giá độ chính xác và tính phù hợp của mô hình với mục tiêu.\n",
    "6\tDeployment\tTriển khai mô hình vào thực tế (ứng dụng, báo cáo, hệ thống...).\n",
    "\n",
    "🟢 Mục tiêu: Tạo ra tri thức có giá trị kinh doanh từ dữ liệu thô.\n",
    "\n",
    "🔹 SEMMA (Sample, Explore, Modify, Model, Assess)\n",
    "\n",
    "Là quy trình được SAS Institute phát triển, tập trung chủ yếu vào các bước kỹ thuật xử lý dữ liệu.\n",
    "\n",
    "Giai đoạn\tÝ nghĩa\tNội dung\n",
    "S\tSample\tLấy mẫu dữ liệu đại diện cho toàn bộ tập dữ liệu.\n",
    "E\tExplore\tKhám phá dữ liệu, phân tích mối quan hệ và xu hướng.\n",
    "M\tModify\tLàm sạch, chọn biến, tạo đặc trưng mới.\n",
    "M\tModel\tXây dựng mô hình dự đoán hoặc phân loại.\n",
    "A\tAssess\tĐánh giá kết quả mô hình, so sánh các phương án.\n",
    "\n",
    "🔸 Khác biệt:\n",
    "\n",
    "CRISP–DM: bao gồm cả khía cạnh kinh doanh và kỹ thuật.\n",
    "\n",
    "SEMMA: chỉ tập trung vào phần kỹ thuật khai phá dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c868e29",
   "metadata": {},
   "source": [
    "Câu 2: Cây quyết định hoạt động như thế nào? Giải thích các thành phần chính và cách cây dự đoán\n",
    "\n",
    "Cây quyết định (Decision Tree) là mô hình học có giám sát, được dùng cho phân loại (classification) hoặc hồi quy (regression).\n",
    "Mô hình hoạt động bằng cách chia dữ liệu thành các nhánh nhỏ dựa trên các điều kiện.\n",
    "\n",
    "🔹 Thành phần chính:\n",
    "\n",
    "Nút gốc (Root Node): Nơi bắt đầu của cây, chứa toàn bộ dữ liệu.\n",
    "\n",
    "Nút trung gian (Internal Node): Nơi dữ liệu được chia nhỏ dựa trên điều kiện của thuộc tính.\n",
    "\n",
    "Nút lá (Leaf Node): Kết quả cuối cùng (nhãn hoặc giá trị dự đoán).\n",
    "\n",
    "Nhánh (Branch): Đường nối giữa các nút, thể hiện điều kiện phân tách.\n",
    "\n",
    "🔹 Cách cây đưa ra dự đoán:\n",
    "\n",
    "Nhận dữ liệu mới làm đầu vào.\n",
    "\n",
    "So sánh giá trị của dữ liệu với các điều kiện từ nút gốc xuống các nút con.\n",
    "\n",
    "Khi đi đến nút lá cuối cùng, cây sẽ đưa ra nhãn hoặc giá trị dự đoán tương ứng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51620026",
   "metadata": {},
   "source": [
    "Câu 3: Các tiêu chí phân tách (splitting criteria) trong cây quyết định là gì? Chúng khác nhau ra sao?\n",
    "\n",
    "Khi chia dữ liệu, cây quyết định cần chọn thuộc tính tốt nhất để tách.\n",
    "Các tiêu chí phổ biến gồm:\n",
    "\n",
    "Tiêu chí\tÝ nghĩa\tCông thức / Đặc điểm\tGhi chú\n",
    "Entropy\tĐo độ hỗn loạn của dữ liệu.\t\n",
    "𝐸\n",
    "𝑛\n",
    "𝑡\n",
    "𝑟\n",
    "𝑜\n",
    "𝑝\n",
    "𝑦\n",
    "=\n",
    "−\n",
    "∑\n",
    "𝑝\n",
    "𝑖\n",
    "log\n",
    "⁡\n",
    "2\n",
    "(\n",
    "𝑝\n",
    "𝑖\n",
    ")\n",
    "Entropy=−∑p\n",
    "i\n",
    "\t​\n",
    "\n",
    "log\n",
    "2\n",
    "\t​\n",
    "\n",
    "(p\n",
    "i\n",
    "\t​\n",
    "\n",
    ")\tDùng trong ID3, C4.5.\n",
    "Information Gain (IG)\tLượng thông tin thu được sau khi chia.\t\n",
    "𝐼\n",
    "𝐺\n",
    "=\n",
    "𝐸\n",
    "𝑛\n",
    "𝑡\n",
    "𝑟\n",
    "𝑜\n",
    "𝑝\n",
    "𝑦\n",
    "𝑝\n",
    "𝑎\n",
    "𝑟\n",
    "𝑒\n",
    "𝑛\n",
    "𝑡\n",
    "−\n",
    "∑\n",
    "𝑤\n",
    "𝑖\n",
    "∗\n",
    "𝐸\n",
    "𝑛\n",
    "𝑡\n",
    "𝑟\n",
    "𝑜\n",
    "𝑝\n",
    "𝑦\n",
    "𝑖\n",
    "IG=Entropy\n",
    "parent\n",
    "\t​\n",
    "\n",
    "−∑w\n",
    "i\n",
    "\t​\n",
    "\n",
    "∗Entropy\n",
    "i\n",
    "\t​\n",
    "\n",
    "\tCàng cao càng tốt.\n",
    "Gini Index\tĐo độ thuần khiết (purity).\t\n",
    "𝐺\n",
    "𝑖\n",
    "𝑛\n",
    "𝑖\n",
    "=\n",
    "1\n",
    "−\n",
    "∑\n",
    "𝑝\n",
    "𝑖\n",
    "2\n",
    "Gini=1−∑p\n",
    "i\n",
    "2\n",
    "\t​\n",
    "\n",
    "\tDùng trong CART (Classification And Regression Tree).\n",
    "\n",
    "🔸 Khác biệt chính:\n",
    "\n",
    "Entropy & Information Gain: dùng log₂ → tính toán nặng hơn một chút.\n",
    "\n",
    "Gini Index: tính nhanh hơn, kết quả thường tương đương."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe1ac9",
   "metadata": {},
   "source": [
    "Câu 4: Rừng cây (Random Forest) là gì? Nó khác gì so với cây quyết định đơn lẻ? Tại sao hiệu suất tốt hơn?\n",
    "🔹 Định nghĩa:\n",
    "\n",
    "Random Forest là tập hợp nhiều cây quyết định (ensemble learning).\n",
    "Mỗi cây được huấn luyện trên một mẫu dữ liệu ngẫu nhiên (bootstrap sample) và một tập con đặc trưng ngẫu nhiên.\n",
    "\n",
    "🔹 Khác biệt so với cây quyết định đơn lẻ:\n",
    "Tiêu chí\tCây quyết định\tRandom Forest\n",
    "Dữ liệu huấn luyện\tMột tập dữ liệu duy nhất\tNhiều tập con ngẫu nhiên\n",
    "Dự đoán\tTừ một cây duy nhất\tTrung bình / Bỏ phiếu từ nhiều cây\n",
    "Overfitting\tDễ bị\tGiảm đáng kể\n",
    "Độ chính xác\tTrung bình\tCao hơn và ổn định hơn\n",
    "🔹 Lý do hiệu suất cao hơn:\n",
    "\n",
    "Vì Random Forest kết hợp nhiều cây độc lập, nên lỗi trung bình được giảm xuống, giúp mô hình chống overfitting và tổng quát hóa tốt hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c14c2d4",
   "metadata": {},
   "source": [
    "Câu 5: Ưu điểm và hạn chế của Decision Tree & Random Forest\n",
    "Mô hình\tƯu điểm\tHạn chế\n",
    "Decision Tree\t- Dễ hiểu, trực quan.\n",
    "- Không cần chuẩn hóa dữ liệu.\n",
    "- Xử lý dữ liệu phân loại & số được.\t- Dễ bị overfit.\n",
    "- Nhạy cảm với dữ liệu nhiễu.\n",
    "- Một thay đổi nhỏ trong dữ liệu có thể làm thay đổi toàn bộ cây.\n",
    "Random Forest\t- Độ chính xác cao.\n",
    "- Giảm overfitting.\n",
    "- Xác định được độ quan trọng của đặc trưng.\t- Tốn thời gian huấn luyện.\n",
    "- Khó diễn giải kết quả.\n",
    "\n",
    "🔸 Cây quyết định hoạt động kém khi dữ liệu có nhiễu, phân bố không đồng đều, hoặc mối quan hệ phi tuyến phức tạp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b78a36d",
   "metadata": {},
   "source": [
    "Câu 6: Code mẫu Python xây dựng mô hình cây quyết định (Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51783aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Tải dữ liệu\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 2. Chia dữ liệu train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Tạo mô hình Decision Tree\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Dự đoán\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 5. Đánh giá kết quả\n",
    "print(\"Độ chính xác:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 6. Vẽ cây\n",
    "plt.figure(figsize=(12,8))\n",
    "plot_tree(model, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127f78d",
   "metadata": {},
   "source": [
    "🔹 Các bước thực hiện:\n",
    "\n",
    "Chuẩn bị và chia dữ liệu.\n",
    "Khởi tạo mô hình cây quyết định.\n",
    "Huấn luyện mô hình (fit).\n",
    "Dự đoán (predict).\n",
    "Đánh giá độ chính xác (accuracy_score).\n",
    "Trực quan hóa cây (plot_tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f92941",
   "metadata": {},
   "source": [
    "Câu 7: Cách triển khai mô hình Random Forest trong Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960bd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,  # số lượng cây\n",
    "    max_depth=None,    # độ sâu tối đa\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Độ chính xác Random Forest:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0decd98a",
   "metadata": {},
   "source": [
    "🔹 Các tham số thường dùng:\n",
    "\n",
    "n_estimators: số cây trong rừng (thường 100–500).\n",
    "max_depth: độ sâu tối đa của mỗi cây.\n",
    "min_samples_split: số mẫu tối thiểu để chia nút.\n",
    "random_state: giúp tái tạo kết quả."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468edd9",
   "metadata": {},
   "source": [
    "Câu 8: Đánh giá tầm quan trọng của đặc trưng (Feature Importance) trong Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a76071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_importances = pd.Series(rf.feature_importances_, index=iris.feature_names)\n",
    "print(feature_importances.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c2a1a",
   "metadata": {},
   "source": [
    "🔹 Ý nghĩa:\n",
    "\n",
    "feature_importances_ cho biết đặc trưng nào có ảnh hưởng lớn nhất đến việc ra quyết định của mô hình.\n",
    "Dữ liệu quan trọng hơn → mô hình dựa vào nó nhiều hơn khi chia nhánh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08540114",
   "metadata": {},
   "source": [
    "Câu 9: Điều chỉnh siêu tham số (Hyperparameter Tuning) bằng GridSearchCV hoặc RandomizedSearchCV\n",
    "🔹 Ví dụ với GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9028e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best accuracy:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e7165a",
   "metadata": {},
   "source": [
    "🔹 Ý nghĩa:\n",
    "GridSearchCV: thử tất cả các tổ hợp tham số để tìm mô hình tốt nhất.\n",
    "RandomizedSearchCV: chọn ngẫu nhiên một số tổ hợp → nhanh hơn khi tập tham số lớn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
