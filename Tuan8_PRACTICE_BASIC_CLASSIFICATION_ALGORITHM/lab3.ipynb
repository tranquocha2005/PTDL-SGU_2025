{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b79376d",
   "metadata": {},
   "source": [
    "2.3. GIẢI THUẬT 3: BAYES NGÂY THƠ (NAÏVE BAYES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692ac90",
   "metadata": {},
   "source": [
    "2.3.1. Ôn tập lý thuyết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f30f8",
   "metadata": {},
   "source": [
    "1. Giải thuật Naive Bayes hoạt động như thế nào?\n",
    "Naive Bayes là một thuật toán phân loại dựa trên định lý Bayes với một giả định \"ngây thơ\" (naive) về tính độc lập của các đặc trưng. Về cơ bản, thuật toán tính xác suất một điểm dữ liệu thuộc về một lớp cụ thể, sau đó gán nó vào lớp có xác suất cao nhất.\n",
    "\n",
    "Định lý Bayes\n",
    "Định lý Bayes mô tả xác suất của một sự kiện, dựa trên kiến thức có trước về các điều kiện có thể liên quan đến sự kiện đó. Công thức như sau:\n",
    "\n",
    "P(A | B) = [P(B | A) * P(A)] / P(B)\n",
    "\n",
    "Trong ngữ cảnh phân loại:\n",
    "\n",
    "y: là lớp (ví dụ: \"Spam\" hoặc \"Không phải Spam\").\n",
    "X: là một tập hợp các đặc trưng (ví dụ: các từ trong email). X = (x₁, x₂, ..., xₙ).\n",
    "Công thức được viết lại là:\n",
    "\n",
    "P(y | X) = [P(X | y) * P(y)] / P(X)\n",
    "\n",
    "Trong đó:\n",
    "\n",
    "P(y | X) (Xác suất hậu nghiệm - Posterior Probability): Xác suất để đối tượng thuộc lớp y khi biết các đặc trưng X. Đây là thứ chúng ta muốn tìm.\n",
    "P(X | y) (Xác suất có điều kiện - Likelihood): Xác suất xuất hiện các đặc trưng X nếu biết đối tượng thuộc lớp y.\n",
    "P(y) (Xác suất tiên nghiệm - Prior Probability): Xác suất của lớp y trong tập dữ liệu.\n",
    "P(X) (Xác suất của bằng chứng - Evidence): Xác suất xuất hiện của các đặc trưng X.\n",
    "Mục tiêu của thuật toán là tìm lớp y sao cho P(y | X) là lớn nhất. Vì P(X) là hằng số đối với tất cả các lớp, ta có thể bỏ qua nó và chỉ cần so sánh P(X | y) * P(y).\n",
    "\n",
    "Giả định \"Ngây thơ\" (Naive Assumption)\n",
    "Đây là bước làm cho thuật toán trở nên \"ngây thơ\". Naive Bayes giả định rằng tất cả các đặc trưng x₁, x₂, ..., xₙ là độc lập với nhau khi biết lớp y.\n",
    "\n",
    "Điều này có nghĩa là sự xuất hiện của một đặc trưng không ảnh hưởng đến sự xuất hiện của đặc trưng khác. Ví dụ, khi phân loại email, thuật toán giả định rằng sự xuất hiện của từ \"miễn phí\" không liên quan đến sự xuất hiện của từ \"khuyến mãi\", mặc dù trong thực tế chúng thường đi cùng nhau.\n",
    "\n",
    "Nhờ giả định này, việc tính toán P(X | y) trở nên cực kỳ đơn giản: P(X | y) = P(x₁ | y) * P(x₂ | y) * ... * P(xₙ | y)\n",
    "\n",
    "Thay vì phải tính một xác suất kết hợp phức tạp, ta chỉ cần tính xác suất của từng đặc trưng riêng lẻ rồi nhân chúng lại với nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda3178",
   "metadata": {},
   "source": [
    "2. Các loại mô hình Naive Bayes và khi nào nên sử dụng\n",
    "Có ba loại mô hình Naive Bayes chính, được phân biệt bởi giả định về phân phối của dữ liệu:\n",
    "\n",
    "Loại mô hình\tĐặc điểm dữ liệu\tGiả định\tVí dụ sử dụng\n",
    "Gaussian Naive Bayes\tĐặc trưng là liên tục (số thực).\tGiả định rằng giá trị của mỗi đặc trưng tuân theo phân phối chuẩn (Gaussian).\t- Phân loại dựa trên chiều cao, cân nặng, nhiệt độ.- Dự đoán điểm tín dụng dựa trên thu nhập, tuổi.\n",
    "Multinomial Naive Bayes\tĐặc trưng là rời rạc, thường là số đếm hoặc tần suất.\tGiả định rằng các đặc trưng tuân theo phân phối đa thức (Multinomial).\t- Phân loại văn bản: đặc trưng là số lần xuất hiện của một từ trong văn bản (Bag-of-Words, TF-IDF).- Phân loại chủ đề tin tức.\n",
    "Bernoulli Naive Bayes\tĐặc trưng là nhị phân (binary/boolean), tức là chỉ có giá trị 0 hoặc 1.\tGiả định rằng các đặc trưng tuân theo phân phối Bernoulli.\t- Phân loại văn bản: đặc trưng là sự hiện diện (1) hay vắng mặt (0) của một từ trong văn bản, không quan tâm đến số lần xuất hiện.- Phân tích cảm xúc (sentiment analysis) dựa trên việc một từ khóa tích cực/tiêu cực có xuất hiện hay không."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c26af72",
   "metadata": {},
   "source": [
    "3. Tại sao Naive Bayes được gọi là \"ngây thơ\"?\n",
    "Thuật toán này được gọi là \"ngây thơ\" (naive) chính vì giả định về tính độc lập của các đặc trưng.\n",
    "\n",
    "Trong thực tế, giả định này hầu như luôn sai. Các đặc trưng thường có mối liên hệ với nhau. Ví dụ:\n",
    "\n",
    "Trong phân loại văn bản, các từ \"New\" và \"York\" có khả năng xuất hiện cùng nhau rất cao.\n",
    "Trong chẩn đoán y tế, các triệu chứng như \"sốt\" và \"ho\" thường liên quan đến nhau.\n",
    "Ảnh hưởng đến hiệu suất:\n",
    "\n",
    "Mặt tích cực: Giả định này giúp đơn giản hóa việc tính toán một cách đáng kể. Thay vì tính toán một ma trận hiệp phương sai phức tạp, ta chỉ cần tính xác suất riêng lẻ của từng đặc trưng. Điều này làm cho Naive Bayes:\n",
    "Rất nhanh để huấn luyện và dự đoán.\n",
    "Hoạt động tốt với dữ liệu có số chiều lớn (nhiều đặc trưng), ví dụ như trong phân loại văn bản với hàng nghìn từ.\n",
    "Yêu cầu ít dữ liệu huấn luyện hơn so với các mô hình phức tạp khác.\n",
    "Mặt tiêu cực: Vì giả định này không đúng với thực tế, xác suất hậu nghiệm P(y | X) mà mô hình tính ra thường không chính xác. Tuy nhiên, điều đáng ngạc nhiên là Naive Bayes vẫn thường cho kết quả phân loại tốt. Lý do là nó không cần tính ra xác suất chính xác, mà chỉ cần xác định được lớp nào có xác suất cao hơn các lớp khác."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3bd9a1",
   "metadata": {},
   "source": [
    "4. Ưu điểm và hạn chế của Naive Bayes\n",
    "Ưu điểm\tHạn chế\n",
    "Nhanh và hiệu quả: Tốc độ huấn luyện và dự đoán rất nhanh.\tGiả định độc lập \"ngây thơ\": Giả định này hiếm khi đúng trong thực tế, có thể làm giảm độ chính xác nếu các đặc trưng phụ thuộc mạnh vào nhau.\n",
    "Yêu cầu ít dữ liệu: Hoạt động tương đối tốt ngay cả với tập dữ liệu nhỏ.\tVấn đề xác suất bằng 0 (Zero-Frequency Problem): Nếu một đặc trưng chưa từng xuất hiện cùng một lớp trong tập huấn luyện, xác suất của nó sẽ bằng 0, làm cho toàn bộ xác suất hậu nghiệm của lớp đó bằng 0. (Có thể khắc phục bằng kỹ thuật Laplace Smoothing).\n",
    "Hoạt động tốt với dữ liệu nhiều chiều: Rất phù hợp cho các bài toán có số lượng đặc trưng lớn như phân loại văn bản.\tKhó biểu diễn mối quan hệ phức tạp: Không thể nắm bắt được sự tương tác giữa các đặc trưng, không hiệu quả bằng SVM hay Random Forest trên các tập dữ liệu có cấu trúc phức tạp.\n",
    "Dễ triển khai và diễn giải: Logic của thuật toán khá đơn giản.\tHiệu suất kém với dữ liệu liên tục: Gaussian NB giả định dữ liệu tuân theo phân phối chuẩn, nếu không đúng thì kết quả sẽ kém.\n",
    "So với SVM hoặc Random Forest:\n",
    "\n",
    "Naive Bayes nhanh hơn, đơn giản hơn và phù hợp cho các bài toán cơ bản, đặc biệt là phân loại văn bản.\n",
    "SVM và Random Forest thường cho độ chính xác cao hơn trên các tập dữ liệu phức tạp vì chúng có thể mô hình hóa các mối quan hệ phi tuyến và tương tác giữa các đặc trưng. Tuy nhiên, chúng đòi hỏi nhiều tài nguyên tính toán và dữ liệu hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd72ef",
   "metadata": {},
   "source": [
    "5. Code mẫu xây dựng mô hình Gaussian Naive Bayes\n",
    "Dưới đây là đoạn code Python sử dụng thư viện Scikit-learn để xây dựng một mô hình Gaussian Naive Bayes đơn giản."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0584ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng mẫu dữ liệu: 150\n",
      "Số lượng đặc trưng: 4\n",
      "Các lớp: [0 1 2]\n",
      "\n",
      "Kích thước tập huấn luyện: (120, 4)\n",
      "Kích thước tập kiểm tra: (30, 4)\n",
      "\n",
      "Đã huấn luyện xong mô hình Gaussian Naive Bayes!\n",
      "\n",
      "Độ chính xác của mô hình: 1.00\n",
      "\n",
      "Báo cáo phân loại (Classification Report):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Ma trận nhầm lẫn (Confusion Matrix):\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Dự đoán cho mẫu mới [[5.1 3.5 1.4 0.2]]: Lớp 'setosa'\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Import các thư viện cần thiết\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Bước 2: Tải và chuẩn bị dữ liệu\n",
    "# Sử dụng bộ dữ liệu Iris nổi tiếng làm ví dụ\n",
    "# Dữ liệu gồm 4 đặc trưng (liên tục) và 3 lớp hoa\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # Đặc trưng (features)\n",
    "y = iris.target # Nhãn (labels)\n",
    "\n",
    "# In ra để xem qua dữ liệu\n",
    "print(\"Số lượng mẫu dữ liệu:\", X.shape[0])\n",
    "print(\"Số lượng đặc trưng:\", X.shape[1])\n",
    "print(\"Các lớp:\", np.unique(y))\n",
    "\n",
    "# Bước 3: Chia dữ liệu thành tập huấn luyện (train) và tập kiểm tra (test)\n",
    "# 80% cho huấn luyện, 20% cho kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nKích thước tập huấn luyện:\", X_train.shape)\n",
    "print(\"Kích thước tập kiểm tra:\", X_test.shape)\n",
    "\n",
    "# Bước 4: Xây dựng và huấn luyện mô hình Gaussian Naive Bayes\n",
    "# Khởi tạo mô hình\n",
    "model = GaussianNB()\n",
    "\n",
    "# Huấn luyện mô hình trên tập train\n",
    "model.fit(X_train, y_train)\n",
    "print(\"\\nĐã huấn luyện xong mô hình Gaussian Naive Bayes!\")\n",
    "\n",
    "# Bước 5: Đánh giá hiệu suất của mô hình\n",
    "# Dự đoán nhãn cho tập test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Tính toán độ chính xác\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nĐộ chính xác của mô hình: {accuracy:.2f}\")\n",
    "\n",
    "# In ra các chỉ số đánh giá khác\n",
    "print(\"\\nBáo cáo phân loại (Classification Report):\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "\n",
    "print(\"\\nMa trận nhầm lẫn (Confusion Matrix):\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Bước 6: Sử dụng mô hình để dự đoán cho dữ liệu mới\n",
    "# Ví dụ một bông hoa mới có các số đo [5.1, 3.5, 1.4, 0.2]\n",
    "new_flower = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
    "prediction = model.predict(new_flower)\n",
    "predicted_class_name = iris.target_names[prediction[0]]\n",
    "\n",
    "print(f\"\\nDự đoán cho mẫu mới {new_flower}: Lớp '{predicted_class_name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0364b44",
   "metadata": {},
   "source": [
    "6. Xử lý dữ liệu phân loại (Categorical Data) cho Multinomial Naive Bayes\n",
    "Multinomial Naive Bayes yêu cầu đầu vào là các giá trị số (thường là số đếm). Do đó, dữ liệu dạng chuỗi (categorical) cần được chuyển đổi. Hai phương pháp phổ biến là:\n",
    "\n",
    "One-Hot Encoding: Biến mỗi giá trị của một cột categorical thành một cột nhị phân mới. Cách này không phù hợp với Multinomial NB vì nó tạo ra các đặc trưng nhị phân (phù hợp hơn với Bernoulli NB) và làm tăng số chiều dữ liệu.\n",
    "\n",
    "Count Vectorizing (Bag-of-Words): Đây là phương pháp chính được sử dụng, đặc biệt trong phân loại văn bản.\n",
    "\n",
    "Tạo từ điển: Xây dựng một từ điển chứa tất cả các từ (token) duy nhất trong toàn bộ văn bản.\n",
    "Vector hóa: Biến mỗi văn bản thành một vector số. Mỗi phần tử trong vector tương ứng với một từ trong từ điển và giá trị của nó là số lần từ đó xuất hiện trong văn bản.\n",
    "Thư viện Scikit-learn cung cấp CountVectorizer để thực hiện việc này một cách dễ dàng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd3b709",
   "metadata": {},
   "source": [
    "7. Triển khai Naive Bayes cho phân loại văn bản\n",
    "Đây là ứng dụng kinh điển và rất hiệu quả của Naive Bayes (thường là Multinomial hoặc Bernoulli).\n",
    "\n",
    "Quy trình thực hiện:\n",
    "\n",
    "Thu thập và tiền xử lý dữ liệu:\n",
    "\n",
    "Thu thập các văn bản và nhãn tương ứng (ví dụ: email và nhãn \"spam\"/\"ham\").\n",
    "Làm sạch văn bản: Chuyển thành chữ thường, loại bỏ dấu câu, số, và các từ dừng (stop words) như \"và\", \"là\", \"của\",...\n",
    "Trích xuất đặc trưng (Feature Extraction):\n",
    "\n",
    "Sử dụng CountVectorizer (cho Multinomial NB) hoặc TfidfVectorizer từ Scikit-learn để biến các văn bản đã làm sạch thành các vector số.\n",
    "CountVectorizer: Đếm tần suất xuất hiện của từ (Bag-of-Words).\n",
    "TfidfVectorizer: Tính trọng số TF-IDF (Term Frequency-Inverse Document Frequency), giúp giảm trọng số của các từ phổ biến và tăng trọng số của các từ quan trọng, đặc trưng cho văn bản.\n",
    "Chia dữ liệu: Chia tập dữ liệu đã vector hóa thành tập huấn luyện và tập kiểm tra.\n",
    "\n",
    "Huấn luyện mô hình:\n",
    "\n",
    "Khởi tạo mô hình MultinomialNB.\n",
    "Huấn luyện mô hình trên tập huấn luyện. Một điểm quan trọng của MultinomialNB là tham số alpha (mặc định là 1.0), dùng cho kỹ thuật Laplace/Lidstone smoothing để giải quyết vấn đề xác suất bằng 0.\n",
    "Đánh giá mô hình:\n",
    "\n",
    "Dùng mô hình đã huấn luyện để dự đoán trên tập kiểm tra.\n",
    "Đánh giá hiệu suất bằng các chỉ số như accuracy, precision, recall, F1-score.\n",
    "Sử dụng: Dùng mô hình để phân loại các văn bản mới.\n",
    "\n",
    "Hy vọng những giải thích trên sẽ giúp bạn hiểu rõ hơn về thuật toán Naive Bayes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ffe80",
   "metadata": {},
   "source": [
    "Nhiệm vụ 1: Phân loại sử dụng Naïve Bays\n",
    "1. Import thư viện và nạp dữ liệu vào notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "480043b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      0\n",
       "1        2      0\n",
       "2        3      0\n",
       "3        4      0\n",
       "4        5      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the Necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "#display the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7409145",
   "metadata": {},
   "source": [
    "2. Xử lý dữ liệu trước khi xây dựng mô hình từ dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3b25417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns with NaN values\n",
    "data = data.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,errors='ignore')\n",
    "# Rename columns for clarity:\n",
    "data.columns = ['label', 'text']\n",
    "# Separate features (X) and target labels (y)\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "# Split the data into training and testing sets (80% training, 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031fc05a",
   "metadata": {},
   "source": [
    "3. Xây dựng vector hóa nội dung HAM | SPAM của tập train và tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e318eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\".csv\", encoding='utf-8')\n",
    "\n",
    "# Giữ đúng cột text\n",
    "data = data[['label', 'message']]\n",
    "data.columns = ['label', 'text']\n",
    "data['text'] = data['text'].fillna('').astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db086e4c",
   "metadata": {},
   "source": [
    "4. Xây dựng mô hình Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948051b6",
   "metadata": {},
   "source": [
    "5. Đánh giá hiệu quả của mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ad6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix,\n",
    "classification_report\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
